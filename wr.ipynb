{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Telemetry Hello World\"\n",
    "authors:\n",
    "- vitillo\n",
    "tags:\n",
    "- tutorial\n",
    "- examples\n",
    "- telemetry\n",
    "- spark\n",
    "created_at: 2016-03-10\n",
    "updated_at: 2018-05-25\n",
    "tldr: Brief introduction to Spark and Telemetry in Python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telemetry Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very a brief introduction to Spark and Telemetry in Python. You should have a look at the [tutorial](https://gist.github.com/vitillo/25a20b7c8685c0c82422) in Scala and the associated [talk](http://www.slideshare.net/RobertoAgostinoVitil/spark-meets-telemetry) if you are interested to learn more about Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from moztelemetry.dataset import Dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Dataset API to fetch data.  Documentation can be found at: https://python-moztelemetry.readthedocs.io/en/stable/api.html#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this example is to plot the startup distribution for each OS. Let's see how many parallel workers we have at our disposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the schema of the dataset we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'submissionDate',\n",
       " u'sourceName',\n",
       " u'sourceVersion',\n",
       " u'docType',\n",
       " u'appName',\n",
       " u'appUpdateChannel',\n",
       " u'appVersion',\n",
       " u'appBuildId']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_source('telemetry').schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Dataset of Telemetry submissions for a given submission date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pings_dataset = (\n",
    "    Dataset.from_source('telemetry')\n",
    "    .where(docType='main')\n",
    "    .where(appBuildId='20180721100146')\n",
    "    .where(appUpdateChannel=\"nightly\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the properties we need and then take a 10% sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: THIS IS NOT A REPRESENTATIVE SAMPLE.\n",
      "This 'sampling' is based on s3 files and is highly\n",
      "susceptible to skew. Use only for quicker performance\n",
      "while prototyping.\n",
      "fetching 16.60107MB in 5 files...\n"
     ]
    }
   ],
   "source": [
    "pings = (\n",
    "    pings_dataset\n",
    "    .select(\n",
    "        'clientId',\n",
    "        GC_MARK_MS_content='payload.processes.content.histograms.CONTENT_PAINT_TIME.values',\n",
    "        osName='environment.system.os.name',\n",
    "        gfx='environment.system.gfx')\n",
    "    .records(sc, sample=0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt: KeyboardInterrupt() in <function <lambda> at 0x7f92caf03668> ignored\n",
      "Exception KeyboardInterrupt: KeyboardInterrupt() in <function <lambda> at 0x7f9288bfb578> ignored\n",
      "Exception KeyboardInterrupt: KeyboardInterrupt() in <function <lambda> at 0x7f9288bfb578> ignored\n",
      "Exception KeyboardInterrupt: KeyboardInterrupt() in <function <lambda> at 0x7f9288bfb578> ignored\n",
      "Exception KeyboardInterrupt: KeyboardInterrupt() in <function <lambda> at 0x7f92caf03668> ignored\n",
      "Process Process-39:\n",
      "Process Process-46:\n",
      "Exception KeyboardInterrupt: KeyboardInterrupt() in <function <lambda> at 0x7f9288bfb578> ignored\n",
      "Process Process-48:\n",
      "Process Process-40:\n",
      "Traceback (most recent call last):\n",
      "Process Process-29:\n",
      "Process Process-47:\n",
      "Process Process-36:\n",
      "Traceback (most recent call last):\n",
      "Process Process-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process Process-38:\n",
      "Process Process-33:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process Process-27:\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "Process Process-45:\n",
      "Process Process-42:\n",
      "Process Process-35:\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Process Process-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "Process Process-30:\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "Process Process-28:\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process Process-25:\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    call_item = call_queue.get(block=True)\n",
      "    call_item = call_queue.get(block=True)\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    call_item = call_queue.get(block=True)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    call_item = call_queue.get(block=True)\n",
      "    call_item = call_queue.get(block=True)\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    self._rlock.acquire()\n",
      "    call_item = call_queue.get(block=True)\n",
      "    self._rlock.acquire()\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "    self._rlock.acquire()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    call_item = call_queue.get(block=True)\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 117, in get\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    call_item = call_queue.get(block=True)\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    call_item = call_queue.get(block=True)\n",
      "    self._rlock.acquire()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/mnt/anaconda2/lib/python2.7/site-packages/concurrent/futures/process.py\", line 122, in _process_worker\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "KeyboardInterrupt\n",
      "    call_item = call_queue.get(block=True)\n",
      "    res = self._recv()\n",
      "KeyboardInterrupt\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    self._rlock.acquire()\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "    call_item = call_queue.get(block=True)\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "KeyboardInterrupt\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/mnt/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "pings = (\n",
    "    pings_dataset\n",
    "    .records(sc, sample=0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out submissions with an invalid startup time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pings.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two extra steps. The first rewrites the ping to have some\n",
    "# information more easily accessible (like the primary adapter),\n",
    "# and the second step removes any pings that don't have adapter\n",
    "# information.\n",
    "def rewrite_ping(p):\n",
    "    adapters = p.get('gfx', None).get('adapters', None)\n",
    "    if not adapters:\n",
    "        return None\n",
    "    adapter = adapters[0]\n",
    "            \n",
    "    p['adapter'] = adapter\n",
    "            \n",
    "    # Convert the version to a tuple of integers.\n",
    "    #if 'driverVersion' in adapter:\n",
    "    #    p['driverVersion'] = [int(n) for n in adapter['driverVersion'].split('.') if n.isdigit()]\n",
    "    return p\n",
    "\n",
    "def filter_ping(p):\n",
    "    return 'adapter' in p\n",
    "rpings = pings.map(rewrite_ping).filter(filter_ping)\n",
    "rpings = rpings.cache()\n",
    "rpings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpings.filter(lambda p: p['adapter']['GPUActive'] == True).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent pseudoreplication, let's consider only a single submission for each client. As this step requires a distributed shuffle, it should always be run only after extracting the attributes of interest with *Dataset.select()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = (\n",
    "    rpings\n",
    "    .map(lambda p: (p['clientId'], p))\n",
    "    .reduceByKey(lambda p1, p2: p1)\n",
    "    .map(lambda p: p[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching is fundamental as it allows for an iterative, real-time development workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached = subset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many pings are we looking at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib2\n",
    "\n",
    "gpu_db = json.load(urllib2.urlopen('https://raw.githubusercontent.com/jrmuizel/gpu-db/master/nvidia.json'))\n",
    "devices = {}\n",
    "for gen in gpu_db['10de'].items():\n",
    "    for chipset in gen[1].items():\n",
    "        for dev in chipset[1]:\n",
    "            #print dev, gen[0]\n",
    "            devices[int(dev,16)] = chipset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nvidia = cached.filter(lambda p: p[\"adapter\"][\"vendorID\"] == '0x10de')\n",
    "nvidia.map(lambda p: \"mobile\" if devices[int(p['adapter']['deviceID'], 16)].endswith(\"M\") else \"desktop\").countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrQualified = nvidia.filter(lambda p: p[\"gfx\"][\"features\"][\"wrQualified\"][\"status\"] == \"available\" )\n",
    "wrQualified.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrQualified.map(lambda p: p[\"gfx\"][\"features\"][\"compositor\"]).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = nvidia.filter(lambda p: devices[int(p['adapter']['deviceID'], 16)].endswith(\"M\"))\n",
    "mobile.map(lambda p: len(p['adapters'])).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile.filter(lambda p: len(p['adapters'])> 1).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = nvidia.filter(lambda p: not devices[int(p['adapter']['deviceID'], 16)].endswith(\"M\"))\n",
    "desktop.map(lambda p: len(p['adapters'])).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.filter(lambda p: len(p['adapters'])> 1).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's group the startup timings by OS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    cached\n",
    "    .map(lambda p: (p['osName'], p['firstPaint']))\n",
    "    .groupByKey()\n",
    "    .collectAsMap()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({x: np.log10(pd.Series(list(y))) for x, y in grouped.items()})\n",
    "plt.figure(figsize=(17, 7))\n",
    "frame.boxplot(return_type='axes')\n",
    "plt.ylabel('log10(firstPaint)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('startup distribution for Windows')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('log10(firstPaint)')\n",
    "frame['Windows_NT'].plot(kind='hist', bins=50, figsize=(14, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract a histogram of GC_MARK_MS (time spent running JS garbage collection mark phase) from the submissions:\n",
    "\n",
    "(see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management for more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histograms = (\n",
    "    pings_dataset\n",
    "    .select(GC_MARK_MS_content='payload.processes.content.histograms.GC_MARK_MS.values',\n",
    "            GC_MARK_MS_parent='payload.histograms.GC_MARK_MS.values')\n",
    "    .records(sc, sample=0.05)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `payload.histograms.GC_MARK_MS.values` is a path to the GC_MARK_MS values of the parent (main) process\n",
    "- `payload.processes.content.histograms.GC_MARK_MS.values` is a path to the GC_MARK_MS values of the child processes\n",
    "\n",
    "Let's aggregate the histogram over all submissions and plot it as a histogram.  Since the parent and child processes are recorded separately, we can create a histogram for each one and then add them together.\n",
    "\n",
    "Each histogram is a pandas series where the index is the bucket and the value is the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def aggregate_series(s1, s2):\n",
    "    \"\"\"Function to sum up series; if one is None, return other\"\"\"\n",
    "    if s1 is None:\n",
    "        return s2\n",
    "    if s2 is None:\n",
    "        return s1\n",
    "    return s1.add(s2, fill_value=0)\n",
    "\n",
    "aggregated_content = (\n",
    "    histograms\n",
    "    .map(lambda p: pd.Series(p['GC_MARK_MS_content']))\n",
    "    .reduce(aggregate_series)\n",
    ")\n",
    "aggregated_content.index = [int(i) for i in aggregated_content.index]\n",
    "aggregated_content = aggregated_content.sort_index()\n",
    "\n",
    "aggregated_parent = (\n",
    "    histograms\n",
    "    .map(lambda p: pd.Series(p['GC_MARK_MS_parent']))\n",
    "    .reduce(aggregate_series)\n",
    ")\n",
    "aggregated_parent.index = [int(i) for i in aggregated_parent.index]\n",
    "aggregated_parent = aggregated_parent.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('GC_MARK_MS_content')\n",
    "aggregated_content.plot(kind='bar', figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('GC_MARK_MS_parent')\n",
    "aggregated_parent.plot(kind='bar', figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also aggregate the values of the parent and children processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('GC_MARK_MS')\n",
    "(aggregated_content + aggregated_parent).plot(kind='bar', figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyed histograms follow a similar pattern. To extract a keyed histogram for which we know the key/label we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyed_hist = (\n",
    "    pings_dataset\n",
    "    .select(redirects='payload.keyedHistograms.NETWORK_HTTP_REDIRECT_TO_SCHEME.https.values')\n",
    "    .records(sc, sample=0.05)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add up the counts of every ping and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregated = (\n",
    "    keyed_hist\n",
    "    .filter(lambda p: p['redirects'] is not None)\n",
    "    .map(lambda p: pd.Series(p['redirects']))\n",
    "    .reduce(lambda c1, c2: c1 + c2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregated.plot(kind='bar', figsize=(15, 7))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
